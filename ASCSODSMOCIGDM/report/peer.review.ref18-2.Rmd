---
title: "Exercício de Reprodução de Experimento"
subtitle: "Artigo Original: A Statistical Comparative Study of Different Similarity Measures of Consensus in Group Decision Making"
author: "Tiago Lucas Pereira Clementino"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
abstract: "Um dos objetivos essenciais em problemas de decisão entre especialistas (do inglês Group Decision Models, GDM) é a obtenção de níveis aceitáveis de consenso. Uma solução não consensual pode não ter validade prática. Medir a similaridade entre as soluções apontadas por cada especialista é essencial para trilhar o caminho até o consenso. Decidir como fazer isto é importante para o sucesso neste processo. Em [1] o autor realizou uma comparação entre cinco dos principais (mais usados) modelos de medição da distância aplicados ao consenso (Manhatan, Euclidian, Dice, Cosine e Jacard). Pretendo questionar/validar este estudo, o reproduzindo e analisando utilizando um modelo de regressão aliado a uma análise estatística por intervalos de confiança, metodologia diferente daquela adotada pelo autor."
output:
  pdf_document: 
    pandoc_args: ["-V", "classoption=twocolumn"]
    number_sections: true
    fig_width: 6 
    fig_height: 4.5
  beamer_presentation:
    highlight: haddock
  includes:
    keep_tex: yes
  html_document:
    toc: true
    toc_float: true
    theme: lumen
    fig_width: 6 
    fig_height: 4.5 
  word_document: default
header-includes:
  - \usepackage{multicol}
  - \usepackage{amsfonts,amssymb,amsmath,mathbbol}
  - \usepackage{graphics,graphicx,epsfig}
  - \usepackage{rotating,subfig}
  - \usepackage{caption}
  - \captionsetup[table]{position=bottom}   %% or below
---
\fontsize{11}{18}
\fontseries{b}
\selectfont
```{r setup, message=FALSE, warning=FALSE, echo=FALSE}
library(tidyverse)
library(here)
library(lubridate)
library(boot)
library(knitr)
library(gridExtra)
library(ggExtra)
library(gapminder)
library(ggalt)
library(ggplot2)
library(ggcorrplot)
library(broom)
library(modelr)
theme_set(theme_bw())
options(warn=-1)
```

# Introdução

Soluções voltadas à decisão em grupo (do inglês, Group Decision Making GDM) consistem em escolher a melhor opção de um conjunto de opções viáveis. Decidir qual a melhor opção frequentemente representa um problema complexo, sobretudo quando evolve o consenso entre um grupo de indivíduos.

GDM são modelos onde um grupo de indivíduos mobiliza seus conhecimentos a certa e um problema em busca da melhor solução dentre um conjunto de critérios e alternativas possíveis. Neste contexto, CRP (Consensus Reaching Process) descrevem um processo onde indivíduos engajados na argumentação alteram suas opiniões visando elevar indicados de consenso e satisfação coletivos [14,15]. Para se atingir indicativos aceitáveis de consenso é preciso quantificar e comparar as preferências de cada indivíduo dentre pares de alterativas viáveis. Em tal comparação são aplicadas estratégias matemáticas de medição de distância. Neste contexto as cinco que mais se aplicam são as distâncias de Manhatan, Euclidiana, Dice, Jacard e Cosseno.

Quando mencionamos a palavra consenso nos remetemos imediatamente ao conceito de unanimidade. Porém, nas últimas décadas tem crescido o entendimento de que uma interpretação mais flexível da ideia de consenso refletiria melhor as relações entre os seres humanos. Daí o conceito de Soft Consensus, onde o consenso é representado por um índice entre zero e um.

Soft Consensus pode ser aplicado representando o consenso por quantificadores Fuzzy tais como “most”, “leasthalf” ou “asmany”, ao invés de apenas todos ou nenhum, sempre em função das preferências dos indivíduos. Tal consenso ainda pode ser mensurado usando três estratégias (níveis [ref]): comparação entre pares de alternativas, comparação entre todas as relações ligadas à uma alternativa especifica ou entre todas as alternativas globalmente. Todos os conceitos apresentados até aqui serão tratados com mais detalhes na seção seguinte, caso esta introdução já tenha sido suficiente ou o leitor tenha familiaridade com o assunto, pode avançar da introdução para a seção 3.

Aqui foi feito uma reprodução de um estudo comparativo originalmente reportado em [x]. Os autores do estudo original fizeram uma comparação estatística entre os cinco principais modelos de medição de distância utilizadas no suporte ao consenso. Testes estatísticos pareados utilizando o método não-paramétrico de Wilcoxon foram reportados. Os resultados visavam responder se a aplicação de um ou outro modelo de distância excercia alguma influência no resultado do processo até o consenso. Dentre os fatores do experimento estão o quanficador Fuzzy aplicado, o nível de consenso aplicado, o total de indivíduos, o total de alternativas e o modelo de distância (variável de controle). O experimento original será descrito em detalhes na seção 3.

Para esta reprodução, procurei seguir detalhadamente todos os passos do estudo original, porém aplicado o meu próprio modelo operacional (disponível em [link com nota de rodapé], junto com os scripts da análise, um guia de procedimento e até o texto deste relatório) e métodos estatísticos diferentes. Para o modelo operacional foi utilizado a plataforma R e a IDE RStudio. O código fonte utilizou como base um software livre de apoio ao consenso chamado GDMR (Group Decision Making R) [ref]. A análise procedeu com base em duas abordagens. Uma utilizando intervalos de confiança com *bootstrap* e o método BCA (do inglês *Bias Corrected Accelerated*) para reproduzir exatamente o mesmo quadro do artigo original (que utilizou o teste de Wilcoxon) e outra utilizou regressão para criar um modelo de correlação entre todos os fatores. Os detalhes desta reprodução estão descritos na seção 4 e a seção 5 traz resultados, comparações, conclusões e questionamentos.
```{r read, include=FALSE}
consensus = read_csv(here::here("./ASCSODSMOCIGDM/data/data2.csv"))
```

# Contexto

Para contextualizar e tornar este documento alto suficiente, vamos esclarecer alguns conceitos que nortearam o experimento original e a reprodução.

## GMD (*Group Decision Making*)

GMD é o processo que visa atingir um julgamento comum a um conjunto de múltiplos participantes para um problema de decisão, o qual é definido por um conjunto de possíveis soluções (preestabelecidas ou não). De acordo com [46], GMD pode ser formalmente definido do seguinte modo:

..* Um grupo de participantes, $E=\{e_1,e_2,...,e_m\}$, cada um deles com um certo grau de conhecimento referente ao domínio do problema.

..* Um problema de decisão definido por n possíveis alternativas, o qual é denotado por $X=\{x_1,x_2,...,x_n\}$.

..* O processo onde os participantes tentam chegar a uma solução comum.

Para cada participante $e_i∈E$, construa a função ${{μ}_p}_i X×X→D$, onde D é o domínio de representação da informação (em $[0,1]$) e ${{μ}_p}_i (x_l,x_k )=(p_{lk})^i (l,k∈\{1,2,...,n\})$ denota o grau de preferência da alternativa $x_l$ frente à $x_k$ em $D$ e $p_{ij}+p_{ji}=1,\forall i,j∈\{1,…,n\}$. Assim, as preferências dos participantes para todas as alternativas em $X$ podem ser descritas como uma matriz $P^i=(p_{lk}^i )_{(n×n)}$[46].

O uso de um modelo fixo de opinião baseado em preferências sobre alternativas é prática comum na literatura [30-32]. Diferentes métodos de avaliação são comparados em [38 do artigo], onde conclui-se que estratégias pareadas de comparação são mais eficientes que não pareadas. Dentre os modelos de representação das preferências dos participantes, aqueles baseados em relações de preferência Fuzzy [8, 9, 29, 34, 39, 46 no artigo] são os mais usuais no suporte ao consenso. Isto se dá em função do processo de agregação de preferências, convenientemente facilitado por quantificadores Fuzzy capazes de expressar imprecisão.

## CRP (*Consensus Reaching Process*)

Um processo de decisão em grupo pode ser resolvido apenas levantando e agregando opiniões dos participantes e, em seguida, selecionando diretamente a solução mais recorrente. Porém, a aprovação e consequente aplicação desta solução não pode estar assegurada pois não houve um consenso entre os especialistas [41]. O consenso nada mais é do que que a discussão em si, um processo recorrente e interativo onde um índice de consenso é checado a cada “rodada”.

Consenso pode ser definido como “um entendimento mutuo produzido com o consentimento de todos os membros em um grupo ou entre vários grupos” [42]. Em um primeiro momento, a ideia de consenso pode nos remeter ao conceito de unanimidade, e nos primeiros trabalhos de pesquisa na área era este o objetivo [48,49]. Atualmente há um entendimento geral de que um conceito mais flexível de consenso (soft consensus) representa melhor a realidade das discussões humanas [50]. A lógica difusa (fuzzy logic) é um caminho recorrente neste sentido [46].

A cada rodada o processo de suporte ao consenso calcula dois parâmetros [4, 22, 23 no artigo]: (i) o índice de consenso que vai definir o quão próximo estamos de um limiar estipulado como aceitável (ii) uma medida de proximidade entre as preferências dos participantes, o que dará suporte ao processo rumo ao consenso. Estas medidas são utilizadas para mensurar o estágio do consenso em três diferentes nível de relações de preferência Fuzzy: preferências entre pares de alternativas (pairs of alternatives no artigo original), todas as relações ligadas a cada alternativa específica (alternatives level no artigo original) e uma medida geral (relation level no artigo original). Isto nos permite identificar quais indivíduos estão mais próximos da solução consensual, ou a respeito de quais alternativas o consenso será mais difícil.

O cálculo do índice de consenso envolve, necessariamente, alguma métrica de distância ou, preferivelmente, similaridade. Uma função de similaridade deve ser utilizada para mensurar ambos, o índice de consenso e uma matriz de proximidade.

Proximidade é calculada mensurando a similaridade entre as preferências entre pares de alternativas para cada participante r em uma matriz de similaridade de acordo com $SM^r=({sm_{ij}}^r)$, onde $${sm_{ij}}^r=s({p_{ij}}^r,p_{ij} )$$
Sendo ${p_{ij}}^r$ a medida da preferência do participante $r$ entre as alternativas $i,j\in X$, e  $p_{ij}=\phi({p_{ij}}^1,...,{p_{ij}}^{(r-1)},{p_{ij}}^{(r+1)},…,{p_{ij}}^m)$, aqui $ϕ$ é uma função que descreve a maioria segundo um quantificador Fuzzy (no experimento foi usado “*most*”, “*leathalf*” e “*asmany*”) e $s:[0,1]^{(m-1)}×[0,1]^{(m-1)}\implies[0,1]$ é a função de similaridade. Esta matriz de similaridade é útil tanto no calculo do consenso, quanto em prover o feedback necessário para que cada participante possa modificar sua opinião corretamente rumo ao consenso.

O consenso é calculado fundindo cada preferência entre pares de alternativas para cada participante r. Isto é feito segundo três níveis de relações de preferência Fuzzy.

..* Nível 1: Consenso entre pares de alternativas, $cp_{ij}$, é um valor obtido pela agregação (utilizando os quantificadores Fuzzy) de todas as preferências dos participantes para cada par de alternativas $$∀i,j=1,...,n\wedge i\neq j:cp_{ij}=\phi({sm_{ij}}^1,...,{sm_{ij}}^m)$$
..* Nível 2: Consenso pela agregação de todas as relações ligadas a uma alternativa específica $$ca_i=\phi(cp_{ij},cp_{ji}:j=1,...,n\wedge j\neq i)$$
..* Nível 3: Consenso por uma medida global envolvendo todos os participantes e alternativas $$cr=\phi(ca_i:i=1,...,n)$$

Atualmente, pelo menos 90 diferentes famílias de operadores de agregação tem sido estudadas [11,12,17,19,21,35,51,52,55,56 no artigo]. Dentre elaaas, o operador OWA (do inglês *Ordered Weighted Averaging*) porposto por Yager [52 no artigo] é o mais usado. A operação de agregação em função de um operador quantificador, $\phi$ é definida assim: $$p_{ij}^c=\phi(p_{ij}^1,...,p_{ij}^m)=\sum_{k=1}^{m}w_k\cdot p_{ij}^{\sigma(k)}$$, onde $\phi$ é uma função de permutação tal que $p_{ij}^{\sigma(k)}>p_{ij}^{\sigma(k+1)}, \forall k=1,...,m-1$ e $w_k\in W=\{w_1,...,w_n\}$ é um vetor ponderado obtido a partir dos quantificadores  de maioria Fuzzy descritos anteriormente.


# Experimento original

## Descrição do problema

Dado um problema de decisão, a função de similartidade aplicada entre as preferências dos participantes tem um importante papel na convergênia rumo ao consenso. Isto serviu de motivação para um estudo comparativo que visa responder se o uso de diferentes funções desimilaridade pode ou não afetar o processo de consenso. Além do mais, se for o caso, produzir recomendações aos participantes que os guiem a ajustar ou manter suas opiniões rumo ao consenso em função da similaridade com núcleos de consenso pode tornar a decisão a respeito de qual função usar ainda mais significativa.

### Problema de negócio

Atingir o consenso não é uma tarefa trivial, sobretudo quando lidamos com um número significativo de participantes ou um problema complexo (muitas alternativas). Identificar uma forma eficáz de mensuar o consenso ou mesmo produzir recomendações úteis pode ser muito difícil. Tomar as decisões corretas no projeto de um sistema de suporte ao consenso é decisivo para esta questão e isto passa por escolher a função de similaridade adequada.

### Problema técnico

Comparar as cinco funções de similaridade mais frequentemente aplicadas a sistemas de suporte ao consenso baseados em quantificadores Fuzzy. Dados dois vetores de números reais $a=(a_1,a_2,...,a_u)$ e $b=(b_1,b_2,...,b_v)$, as cinco funções de similaridade testadas são as seguintes [6,7,15,48 no artigo]: $$Manhatan: d_1(a,b)=\sum_{i=1}^{n}|a_i-b_i|$$$$Euclidean: d_2(a,b)=\sqrt{\sum_{i=1}^{n}{|a_i-b_i|}^2}$$$$Cosine: d_2(a,b)=\frac{{\sum_{i=1}^{n}a_i\cdot b_i}}{\sqrt{\sum_{i=1}^{n}a_i^2}\cdot\sqrt{\sum_{i=1}^{n}b_i^2}}$$$$Dice: d_4(a,b)=\frac{2\cdot\sum_{i=1}^{n}a_i\cdot b_i}{\sum_{i=1}^{n}a_i^2+\sum_{i=1}^{n}b_i^2}$$$$Jaccard: d_5(a,b)=\frac{\sum_{i=1}^{n}a_i\cdot b_i}{\sum_{i=1}^{n}a_i^2+\sum_{i=1}^{n}b_i^2-\sum_{i=1}^{n}a_i^2\cdot\sum_{i=1}^{n}b_i^2}$$

## Objetivos da Investigação

A pesquisa realizada no artigo em questão é do tipo experimental, e teve como objetivo comparar o comportamento das cinco principais funções de similaridade aplicadas a problemas de consenso. Foi realizada uma simulação de consenso a partir de dados aleatórios aplicando tais funções e seus resultados analisados sob a métrica do índice de consenso final.

Formalmente, o objetivo desta comparação pode ser definido no formato GQM como analisar as funções de distância aplicadas ao suporte ao consenso com a intenção de compará-las a respeito de seus índices finais de consenso do ponto de vista dos projetistas de sistemas de suporte ao consenso no contexto dos dados resultantes de uma simulação.

## Execução do experimento

### Questões de pesquisa

"*The application of the Manhattan, Euclidean, Cosine, Dice and Jaccard distance functions in GDM problems do not produce significant differences in the measurement of consensus*" [referencia ao artigo base], traduzindo: "A aplicação das funções de distância de Manhatan, Euclidiana, Cosseno, Dice e Jaccard em problemas GDM não produzem diferenças significativas ao mensurar consenso."

### Fatores e variáveis de resposta

As variáveis independentes (e também fatores) utilizados no experimento são:

..* Função de distância utilizada: Uma dentre cinco funções tomadas como predominantes na literatura (variável de controle).
..* Total de participantes: Número de participantes utilizados no processo de consenso (simulação) $E_m:m=\{4,6,8,10,12\}$.
..* Total de alternativas viáveis: Número de alternativas de solução viáveis $X_n:n=\{4,6,8\}$.
..* Quantificadores Fuzzy: Além das funções de distância, quantificadores de maioria Fuzzy podem ter influência no resultado. Aqui foram usados "most", "asmany" e "leasthalf".
..* Níveis de consenso: São relações de preferência entre alternativas associadas a maioras Fuzzy. São eles: (1) nível de pares de alternativas (compara cada alternativa entre si), (2) nível de alternativas (compara cada alternativa com as demais) e (3) nível da relação (comparação geral)

As variáveis de resposta são:

..* Índice de concenso: Saldo final do processo de consenso que descreve o qual de acordo os participantes estão com o resulta: $cr\in[0,1]$
..* Total de iterações: [use apenas no seu experiento]
..* Diferença entre índice inicial e final de consenso: [use apenas no seu experimento]

### Níveis dos fatores

Os níveis dos fatores estão definidos de acordo com a Tabela 1.

\begin{tabular}{|p{4}|p{4}|}\hline
Fator & Níveis \\ \hline \hline
\bf Função de distância & Manhatan, Euclidean, Cosine, Dice, Jaccard \\ \hline
\bf Participantes & 4, 6, 8, 10, 12 \\ \hline
\bf Alternativas & 4, 6, 8 \\ \hline
\bf Quantificadores & most, leasthalf, asmany \\ \hline
\bf Níveis & 1, 2, 3 \\ \hline
\end{tabular}
\caption{Tabela 1. Definição dos níveis dos fatores.}

### Hipótese nula

A hipótese nula afirma que a utilização de duas funções de distância diferentes não produzem diferenças significativas no nível final de consenso.

### Unidade experimentais

As unidade experimentais são os resultados da comparação entre cada duas funções de distância distintas dados cada combinação diferente de fatores.

### Design do experimento

Trata-se de uma pesquisa experimental. Aqui os dados são produzidos pelo pesquisador com base na repetição de experimentos onde fatores são ajustados e variáveis resposta são observadas. Tipicamente há um ou poucos fatores importantes a ajustar a cada repetição (aqui temos a função de distância e os outro quatro fatores).

Para testar a hipótese acima, doze (12) conjuntos de relações de preferência (pares de alternativas) foram gerados aleatóriamente para cada combinação possível de participantes ($E_m:m\in M=\{4,6,8,10,12\}$) e alternativas ($X_n:n\in N=\{4,6,8\}$). As diferentes funções de distância foram aplicadas, por sua véz, para mensurar consenso nos três níveis possíveis (pares de alternativas, alternativas e relação geral), usando os três diferentes operadores quantificadores guiados OWA [arranje uma referência]. Todas as funções de distância foram testadas aos pares, $d_i\times d_j:i=\{1,2,3,4\},j=\{1,2,3,4,5\}$ ($\frac{5*5-5}{2}=10$ testes), e assim, foram realizadas um total de $12*|M|*|N|*3*3*10=14.200$ repetições.

### Execução

A execução do experimento envolve apenas dois passos:

1. Execução de simulações de consenso. Uma para cada combinação de fatores.
2. Análise estatística dos resultados.

#### Análise dos resultados

Para cada par de funções de distância para comparação foram analisadas duas amostras relacionadas. O usual teste paramétricoutilizado nestes casos é o teste t. Contudo, este teste exige para sua aplicação, que assuma-se uma distribuição normal e independente dos dados na população do qual a amostra aleatória de preferências é retirada. O autor considerou que assumir isto é pouco realista, além de entender que evitando tais premissas poderia tornar seus reultados mais generalistas. Assim, adotou um teste não-paramétrico como sendo o mais adequado [36,45,49 no artigo]

Para dados contínuos e duas amostras relacionadas (pares e alternativas), o autor entendeu como adequado o teste não-paramétrico de ranking de Wilcoxon [14, 36, 42, 45, 49 no artigo]. O teste de Wilcoxon leva em consideração informações a respeito do sinal da diferença e também da magnitude desta para ranqueá-las apropriadamente. O ranking é a pessa chave para qualificação da significacia das diferenças entre os reultados neste método.

#### Instrumentação

Não houveram especificações ligadas a operação de instrumentos.

### Ameaças à validade

#### Ameaças à validade interna

fdgfdgfdg

#### Ameaças à validade de constructo

fdgdfgfdgdf

#### Ameaças à validade externa

dfgfdgfdgfd

## Resultados

sdfsdfdsfds


```{r echo=FALSE, warning=FALSE, message=FALSE}

consensus %>% 
  ggplot(aes(y= `final consensus`, x=distance  , color = quantifier)) + 
  geom_jitter(alpha = .2, width = .2) + 
  geom_boxplot(outlier.alpha = .0) +
  labs(x='Modelo de distância',  
    y='Consenso', 
    title="Índices de consenso medidos por métrica de distância", 
    subtitle="(distance, final consensus)", 
    caption="GDMR",
    color="quantificador") +
  theme(plot.title = element_text(face="bold",size = "17"),
    plot.subtitle = element_text(size = "12"),
    plot.caption = element_text(size="12"),
    axis.title.x = element_text(size ="15"),
    axis.title.y = element_text(size="15"),
    axis.text.x = element_text(size="12"),
    axis.text.y = element_text(size="12"),
    panel.border=element_blank())

```

# Reprodução do Experimento

Precisamos avaliar um conjunto de variáveis em um exercício de visualização de correlações de dados através de marcas e canais. O objetivo de nossa investigação é entender os dados e as relações entre suas variáveis. Tendo isto em vista, é importante ser capaz de escolher as marcas e canais adequados para nossa análise.

A partir disto, devemos propor possíveis correlações alvo ligadas às relações entre variáveis que julguemos interessantes, para em seguida proceder a análise.

# Resultados

De acordo com o enunciado do Laboratório 2 checkpoint 02 da disciplina LPCC2, este documento deve conter gráficos plenamente legíveis (tanto o texto quanto os elementos) para um zoo de 100% em um documento pdf de duas colunas (os gráficos devem ter a largura de uma coluna) e seguir as boas práticas de visualização estudadas. Além de texto descrevendo a tarefa de visualização.

# Considerações

Nossa base de dados conta com variáveis bem intuitivas, cada uma delas descreve alguma característica dos projetos. Vide tabela no final deste documento

Na nossa análise buscaremos uma ou mais características da relação entre as variáveis **sloc\_end** e **sloc\_med**, explorando marcas e canais gráficos. Além de incluirmos eventualmente **activity\_period**, **team** e **lang** para posicionar nossas análises no nosso conjunto de dados.
















## Variáveis de estudo

Selecionamos para este relatório duas variáveis que serão alvo de comparações, medições e visualizações, são elas: **sloc\_end** e **sloc\_med**, outras variáveis também podem ser usadas na comparação como **lang** ou **team**. Nosso objetivo é observar seu comportamento, confirmando ou refutando certas perspectivas de correlação que chamaremos de questões e são descritas abaixo.

# Análise

A partir daqui analisaremos nossos dados com base em questões levantadas a partir de correlações entre variáveis. Neste estudo, o principal foco é a análise visual. Utilizaremos diversas variedades de gráficos estatísticos, canais de visualização e marcas.

Um canal é uma dimensão usada para converter dados de uma tabela em uma visualização gráfica. Um canal pode ser de alta ou baixa magnitude, representando uma eficácia na visualização de informação maior ou menor. 

Nosso primeiro objetivo é entender como o volume de código se comporta ao longo do tempo, e faremos isto comparando as variáveis **sloc\_end** e **sloc\_med**, sempre fazendo um paralelo com variáveis significativas como **lang** e/ou **team**, priorizando canais mais eficazes para variáveis alvo de análise.

## **sloc\_end** e **sloc\_med**

A principal relação entre estas duas variáveis é o tempo. **sloc\_med**, como já foi mencionado, mede o volume de código de um projeto na metade de seu tempo de vida (até o fim da medição dos dados), já **sloc\_end** mede o volume total de código no fim do período de medição. É de se esperar que **sloc\_med** sejá menor que **sloc\_end**, mas qual a proporção desta diferença?

Para começar a responder esta pergunta poderíamos pensar em usar um gráfico de dispersão (*scatter plot*). O gráfico de dispersão posiciona todos os elementos observados como pontos em um plano cartesiano, onde x corresponde a uma variável e y à outra.

Um bom tipo de gráfico para relacionar **sloc\_med** e **sloc\_end** é o *Dumbbell Plot*, que pode ser visto como uma variação do gráfico de dispersão. Nele o canal "posicionamento bidimensional" está representado na forma de pontos em um plano tal como o gráfico de dispersão. Porém, o eixo x apresenta duas variáveis e a progressão de uma até a outra, formando uma linha (o comprimento da linha é mais um canal). Abaixo está um *Dumbbell Plot* onde x descreve a variável **sloc\_med** e a distância entre ela e **sloc\_end**. Incluiremos também as variáveis **lang** e **team** nos canais cor dos pontos e dimensão vertical para posicionar melhor nosso gráfico nos nossos dados.

```{r message=FALSE, warning=FALSE, echo=FALSE}
consensus %>% 
  ggplot(aes(x = `final consensus`)) + 
  geom_histogram(color="white", fill="darkgray") +
  labs(x='Consenso',  
    y='Densidade', 
    title="Densidade de índices de consenso", 
    subtitle="(final consensus, density)") +
  theme(plot.title = element_text(face="bold",size = "17"),
    plot.subtitle = element_text(size = "12"),
    plot.caption = element_text(size="12"),
    axis.title.x = element_text(size ="15"),
    axis.title.y = element_text(size="15"),
    axis.text.x = element_text(size="12"),
    axis.text.y = element_text(size="12"),
    panel.border = element_rect(colour = "white"),
    panel.background = element_rect(fill = "lightgray"))

```

Observando os pontos e traços neste gráfico podemos ter a ideia de que talvez a maior parte do desenvolvimento ocorra entre o início e a primeira metade do projeto. Isto com base na diferença entre o comprimento dos traços que descrevem a distância entre **sloc\_med** e **sloc\_end**, e a distância entre **sloc\_med** e a origem de x. Porém, é uma conclusão muito inicial, pois há muitos pontos aglomerados de difícil visualização, além de alguns pontos com grandes distâncias entre **sloc\_med** e **sloc\_end**.

Uma nova evidência para esta afirmação poderia ser obtida observando não as duas variáveis separadas, mas uma nova variável composta pela proporção entre elas. A fórmula $$\frac{sloc\_med*100}{sloc\_end}$$ nos traz este valor. Novamente, para posicionar melhor nossa visualização nos nossos dados, incluiremos as seguintes três variáveis no gráfico; **team**, **activity\_period** e **lang** nos canais dimensão horizontal, área do ponto e cor, respectivamente. Um *boxplot* para cada um de cem *breaks* (quando diferentes de vazio) ajuda a visualizar a relação.




```{r echo=FALSE}
funcao_bootstrap <- function(data, indexes){
    d = data %>% 
      slice(indexes) %>% 
      group_by(distance) %>% 
      summarise(`final consensus` = median(`final consensus`)) %>% 
      pull(`final consensus`)   
    return(d[1] - d[2])
}

funcao_bootstrap_2 <- function(data_){
    return (boot(data = data_, 
                   statistic = funcao_bootstrap,
                   R = 1000))
}

funcao_bootstrap_distribution <- function(distribution,titleArg){
  
  p1 <- distribution %>% 
  ggplot(aes(x = estatistica)) + 
  geom_histogram(binwidth = .001, fill = "darkgray", color="white") + 
    labs(x=NULL,  
        y=NULL, 
        title=titleArg) +
    theme(plot.title = element_text(face="bold",size = "9"),
        plot.caption = element_text(size="9"),
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.border = element_rect(colour = "white"),
        panel.background = element_rect(fill = "lightgray"))
  
    return (p1)
}

funcao_bootstrap_ci_tibble <- function(ci,m,n,title_,quantifier_,level_){
  
  result <- tibble(statistic = as.double(ci$t0),
                   statistic_count = ifelse(
                     (as.double(ci$basic[4]) > 0.0 & as.double(ci$basic[5]) > 0)|
                     (as.double(ci$basic[4]) < 0.0 & as.double(ci$basic[5]) < 0),1,0),
                   basic_1 = as.double(ci$basic[4]), 
                   basic_2 = as.double(ci$basic[5]), 
                   experts = as.character(m),
                   alternatives = as.character(n),
                   title = title_,
                   quantifier = quantifier_,
                   #level = level_
                   level = ifelse(
                     (as.integer(level_) > 1),
                     ifelse((as.integer(level_) > 2),'Preferências','Alternativas')
                     ,'Pares de alt.')
                   
                   )
  return (result)
}

funcao_bootstrap_ci <- function(bootstraps){
  
  #return (boot.ci(bootstraps, conf = 0.95, type = "basic"))
  return (boot.ci(bootstraps, conf = 0.95, type = "bca"))
}

```

```{r echo=FALSE}

bootstraps_ma_co <- funcao_bootstrap_2(consensus %>% filter(distance == 'manhattan' | distance == 'cosine')) 

bootstraps_ma_eu <- funcao_bootstrap_2(consensus %>% filter(distance == 'manhattan' | distance == 'euclidean'))

bootstraps_ma_di <- funcao_bootstrap_2(consensus %>% filter(distance == 'manhattan' | distance == 'dice'))

bootstraps_ma_ja <- funcao_bootstrap_2(consensus %>% filter(distance == 'manhattan' | distance == 'jacard'))

bootstraps_co_eu <- funcao_bootstrap_2(consensus %>% filter(distance == 'cosine' | distance == 'euclidean'))

bootstraps_co_di <- funcao_bootstrap_2(consensus %>% filter(distance == 'cosine' | distance == 'dice'))

bootstraps_co_ja <- funcao_bootstrap_2(consensus %>% filter(distance == 'cosine' | distance == 'jacard'))

bootstraps_eu_di <- funcao_bootstrap_2(consensus %>% filter(distance == 'euclidean' | distance == 'dice'))

bootstraps_eu_ja <- funcao_bootstrap_2(consensus %>% filter(distance == 'euclidean' | distance == 'jacard'))

bootstraps_di_ja <- funcao_bootstrap_2(consensus %>% filter(distance == 'dice' | distance == 'jacard'))

```

```{r echo=FALSE}

p1 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_ma_co$t)),"Manhattan X Cosine")

p2 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_ma_eu$t)),"Manhattan X Euclidean")

p3 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_ma_di$t)),"Manhattan X Dice")

p4 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_ma_ja$t)),"Manhattan X Jacard")

p5 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_co_eu$t)),"Cosine X Euclidean")

p6 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_co_di$t)),"Cosine X Dice")

p7 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_co_ja$t)),"Cosine X Jacard")

p8 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_eu_di$t)),"Euclidean X Dice")

p9 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_eu_ja$t)),"Euclidean X Jacard")

p10 <- funcao_bootstrap_distribution(tibble(estatistica = as.double(bootstraps_di_ja$t)),"Dice X Jacard")

```

```{r echo=FALSE}

grid.arrange(arrangeGrob(p1,p2,p3,p4,ncol=2,widths=c(1,1)),
    arrangeGrob(p5,p6,p7,p8,p9,p10,ncol=2,widths=c(1,1)),
    heights=c(2,3))
```

No gráfico acima é possível perceber que a maior parte dos pontos está acima de 60%, o que nos leva a concluir que geralmente mais da metade do código é escrito no início do projeto. Além disto, é frequênte, de acordo com o gráfico, projetos com 80% ou 90% do desenvolvimento ocorrido na primeira metade de sua vida. Observando os *bosplots* pode-se perceber apenas um *box* abaixo de 50%, e com apenas um projeto.

Uma visualização mais clara talvez possa vir com um gráfico de dispersão (*scatter plot*) simples, que descreve a posição de cada projeto em um plano cartesiano onde x é o **sloc\_end** e y é **sloc\_med**. Novamente, incluiremos também as variáveis **lang** e **team** nos canais cor e área dos pontos para posicionar melhor nosso gráfico nos nossos dados.

```{r echo=FALSE}

aux=tibble()
M=c(4,6,8,10,12)
N=c(4,6,8)
quantifiers=c("asmany","most","leasthalf")
levels=c(1:3)

#m=6
#m=6
#level=3
#quantifier="asmany"
for (m in M)
{
  for (n in N)
  {
    for (level in levels)
    {
      for (quantifier in quantifiers)
      {
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='manhattan'|distance=='cosine',experts==m,alternatives==n)
            )),
          m,
          n,
          "Manhattan X Cosine",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='manhattan'|distance=='euclidean',experts==m,alternatives==n)
            )),
          m,
          n,
          "Manhattan X Euclidean",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='manhattan'|distance=='dice',experts==m,alternatives==n)
            )),
          m,
          n,
          "Manhattan X Dice",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='manhattan'|distance=='jacard',experts==m,alternatives==n)
            )),
          m,
          n,
          "Manhattan X Jacard",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='cosine'|distance=='euclidean',experts==m,alternatives==n)
            )),
          m,
          n,
          "Cosine X Euclidean",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='cosine'|distance=='dice',experts==m,alternatives==n)
            )),
          m,
          n,
          "Cosine X Dice",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='cosine'|distance=='jacard',experts==m,alternatives==n)
            )),
          m,
          n,
          "Cosine X Jacard",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='euclidean'|distance=='dice',experts==m,alternatives==n)
            )),
          m,
          n,
          "Euclidean X Dice",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='euclidean'|distance=='jacard',experts==m,alternatives==n)
            )),
          m,
          n,
          "Euclidean X Jacard",
          quantifier,
          level))
        aux=bind_rows(aux,funcao_bootstrap_ci_tibble(
          funcao_bootstrap_ci(funcao_bootstrap_2(
            consensus%>%filter(distance=='dice'|distance=='jacard',experts==m,alternatives==n)
            )),
          m,
          n,
          "Dice X Jacard",
          quantifier,
          level))
      }
    }

  }
}

```

Veja a eficácia do canal "posicionamento no plano", apenas com base no gráfico acima já podemos perceber claramente dois atributos desta relação. O primeiro aponta que de fato, como já poderíamos supor, **sloc\_end** é maior que **sloc\_med** aparentemente em todos os casos. Perceba que não há nenhum ponto acima da diagonal principal do nosso gráfico. Neste momento, não podemos garantir que esta afirmação é verdade para todos os casos, pois os canais de visualização geralmente proveem apenas uma direção para a análise. Em buscar de uma resposta categórica, precisamos de um modelo. Veja abaixo.


```{r echo=FALSE}

aux_new <- aux %>% group_by(experts,alternatives,quantifier,level) %>% summarise(statistic_count = sum(statistic_count)) 

aux_new %>%
ggplot(aes(experts, alternatives, fill = statistic_count)) + 
  geom_tile(colour = "white") + 
  facet_grid(level~quantifier) + 
  scale_fill_gradient(low="red", high="green") +
  labs(x="Quantificador",
       y="Nível",
       title = "Matriz de comparações entre métricas de distância", 
       fill="Comparações") +
    theme(plot.title = element_text(face="bold",size = "17"),
        plot.caption = element_text(size="12"),
        axis.title.y = element_text(size="12"),
        axis.title.x = element_text(size="12"),
        axis.text.x = element_text(),
        axis.text.y = element_text(),
        strip.text.y = element_text(angle = 90))

aux_new <- aux %>% group_by(experts,alternatives,quantifier,title) %>% summarise(statistic_count = sum(statistic_count))

aux_new %>%
ggplot(aes(experts, alternatives, fill = statistic_count)) + 
  geom_tile(colour = "white") + 
  facet_grid(title~quantifier) + 
  scale_fill_gradient(low="red", high="green") +
  labs(x="Quantificador",
       y="Comparação",
       title = "Matriz de comparações entre métricas de distância", 
       fill="Níveis") +
    theme(plot.title = element_text(face="bold",size = "17"),
        plot.caption = element_text(size="12"),
        axis.title.y = element_text(size="12"),
        axis.title.x = element_text(size="12"),
        axis.text.x = element_text(angle=60, hjust=1),
        axis.text.y = element_text(angle=90, hjust=1),
        strip.text.y = element_text(angle = 0))





```

Agora podemos afirmar categoricamente que nenhum projeto em nossa base encolheu (refatoramento) entre a metade e o fim de sua vida. O segundo atributo da relação entre estas duas variáveis diz respeito à linearidade. É possível perceber que a figura composta pelos pontos no gráfico forma uma linha muito nítida à quase que exatos 45° de inclinação, bem em cima da diagonal principal do gráfico. Isto sugere que os valores de **sloc\_med** e **sloc\_end** são muito parecidos, o que nos leva a crer que a maior parte do desenvolvimento ocorra na primeira metade da vida dos projetos na nossa base de dados, como os dois gráficos anteriores já demonstravam.

Novamente os canais de visualização nos apontam a direção da análise, mas para responder se a maior parte do desenvolvimento realmente ocorre no início do projeto devemos recorrer aos modelos. Através de um coeficiente de correlação linear entre **sloc\_med** e **sloc\_end** podemos ter a confirmação que buscamos. Nesta correlação sempre retornará um valor entre -1 e 1, onde -1 representa uma perfeita correlação decrescente, 0 a ausência de correlação e 1 representa uma correlação crescente forte. Aqui calculamos a correção entre estas variáveis de três métodos diferentes.

```{r echo=FALSE}


funcao_correlation_matrix <- function(data_,model){
  
  model = lm(model, data = data_ )
  
  g<-glance(model)
  
  return (g$r.squared)
}

aux_models=data.frame()

names<-c("Consenso","Distância","Nível","Quantificador","Alternativas","Especialistas")
values<-c("final consensus","distance","level","quantifier","alternatives","experts")

for(x in 1:6){
  coe=NaN
  if(values[x] != "final consensus"){
    coe=funcao_correlation_matrix(consensus,`final consensus` ~ consensus[[values[x]]])
    aux_models=rbind(aux_models,data.frame(
      "x_"=names[x],
      "y_"="Consenso",
      coe))
  }
 
}


```

```{r echo=FALSE}

aux_models %>% 
  ggplot(aes(y= y_, x=x_, color = coe, size = coe,label=coe)) + 
  geom_point() + 
  geom_text(aes(label=round(coe,3)), size=5, color="black", fontface="bold") +
  scale_size_continuous(range=c(8,20)) +
  scale_color_continuous(low="darkgray",high="green") +
  labs(x=NULL,  
    y=NULL, 
    title="Correlação entre o consenso e demais variáveis", 
    subtitle="(all variables, final consensus)") +
  theme(plot.title = element_text(face="bold",size = "17"),
    plot.subtitle = element_text(size = "12"),
    plot.caption = element_text(size="12"),
    axis.title.x = element_text(size ="15"),
    axis.title.y = element_text(size="15"),
    axis.text.x = element_text(size="12",vjust=1.),
    axis.text.y = element_text(size="12"),
    legend.position = "none",
    panel.border = element_rect(colour = "white"),
    panel.background = element_rect(fill = "lightgray"))

```




```{r echo=FALSE}

modelo = lm(`final consensus` ~ distance + quantifier + level + alternatives + experts, data = consensus )

t_ic <- tidy(modelo, conf.int = TRUE, conf.level = 0.95)

colnames(t_ic) <- c('Termo','Coeficiente','std.error','statistic','P-valor','Limite inf.','Limite sup.')
rownames(t_ic) <- c('',' ','  ','   ','    ','     ','      ','       ','        ' ,'         ')

r2 <- glance(modelo)

colnames(r2) <- c('R quadrado','R quad. ajust.','sigma','statistic','P-valor','df','loglik','AIC','BIC','deviance','df.residual')
rownames(r2) <- c('')

```


```{r}

grid.arrange(
  tableGrob(r2[1:1, c(1,2,5)]),
  tableGrob(t_ic[2:10, c(1,2,5,6,7)]),
  nrow=2,heights=c(1,3))


```

A tabela apresenta os três valores referentes as três formas de calcular a correlação entre as variáveis. Perceba que todos apresentam uma correlação superior a 0.9, o que indica uma forte correlação. Esta evidência responde nossa atual dúvida. De fato, como os gráficos mostraram, a maior parte do desenvolvimento ocorre na primeira metade do projeto.

# Conclusão

Podemos concluir com base nos gráficos e resultados matemáticos, que nenhum projeto teve seu código refatorado a ponto de encolher da metade do tempo de vida do projeto até o fim e que a maior parte do desenvolvimento ocorre, em média, na primeira metade do tempo de vida do projeto.


```{r echo=FALSE}

consensus %>% 
  mutate(consensus=`final consensus`-`initial consensus`) %>%
  ggplot(aes(y= consensus, x=distance  , color = quantifier)) + 
  geom_jitter(alpha = .2, width = .2) + 
  geom_boxplot(outlier.alpha = .0) +
  labs(x='Modelo de distância',  
    y='Consenso', 
    title="Índices de consenso medidos por métrica de distância", 
    subtitle="(distance, final consensus)", 
    caption="GDMR",
    color="quantificador") +
  theme(plot.title = element_text(face="bold",size = "17"),
    plot.subtitle = element_text(size = "12"),
    plot.caption = element_text(size="12"),
    axis.title.x = element_text(size ="15"),
    axis.title.y = element_text(size="15"),
    axis.text.x = element_text(size="12"),
    axis.text.y = element_text(size="12"),
    panel.border=element_blank())

```

Como ameaça à validade desta conclusão, podemos mencionar que a variável **sloc\_end** não representa, de fato, o fim da vida do projeto, mas o fim da medição. Alguns projetos podem ter entrado em produção (quando passar a sofrer muito menos alterações) antes mesmo do momento em que **sloc\_med** foi registrado, outros não terem atingido a maturidade mesmo ao final do tempo total.
\newpage
\begin{multicols}{1}
\begin{center}
\begin{tabular}{c}
\bf {\Large Anexos}
\end{tabular}
\end{center}
\end{multicols}

\begin{multicols}{1}
\begin{tabular}{|l|p{9cm}|l|}\hline
Nome & Descrição & Tipo \\ \hline \hline
\bf gh\_project\_name & nome do projeto & Categórica \\ \hline
\bf team & total de desenvolvedores que participaram do projeto até sua última medição & Numérica \\ \hline
\bf lang & linguagem de programação predominante & Categórica \\ \hline
\bf sloc\_end & total de linhas de código na última medição do projeto & Numérica \\ \hline
\bf sloc\_med & total de linhas de código no meio do tempo de atividade estimado do projeto & Numérica \\ \hline
\bf activity\_period & tempo de atividade estimado do projeto & Numérica \\ \hline
\bf num\_commits & total de submissões de alteração durante todo o tempo de atividade do projeto & Numérica \\ \hline
\bf commits\_per\_month & total de submissões por mês & Numérica \\ \hline
\bf tests\_per\_kloc & casos de teste por total de linhas de código & Numérica \\ \hline
\bf total\_builds & total de integrações & Numérica \\ \hline
\bf build\_success\_prop & proporção de integrações bem-sucedidas & Numérica \\ \hline
\bf builds\_per\_month & total médio de integrações por mês & Numérica \\ \hline
\bf tests\_added\_per\_build & total médio de testes adicionados por integração & Numérica \\ \hline
\bf tests\_successful & total de testes bem-sucedidos & Numérica \\ \hline
\bf test\_density & densidade de testes & Numérica \\ \hline
\bf test\_size\_avg & tamanho médio dos casos de testes & Numérica \\ \hline
\end{tabular}

\end{multicols}

